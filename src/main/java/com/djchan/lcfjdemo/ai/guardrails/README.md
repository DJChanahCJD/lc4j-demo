Guardrails 是允许开发者验证 LLM 输入和输出的机制，可以简单理解为“输入输出拦截器”
如：输入前做敏感词检测，输出前做格式校验等

只有在使用 AI Services 时才可用 guardrails。

官方文档：https://docs.langchain4j.dev/tutorials/guardrails